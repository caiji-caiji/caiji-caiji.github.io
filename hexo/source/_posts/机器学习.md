# 机器学习

##  1.机器学习概念

> ### Two definitions of Machine Learning are offered. 
>
> > ```
> > 提供了机器学习的两种定义。
> > ```
>
> ###### Arthur Samuel described it as: "the field of study that gives computers the ability to learn without being explicitly programmed." This is an older, informal definition.
>
> > ```
> > 亚瑟·塞缪尔（Arthur Samuel）将其描述为：“研究领域使计算机无需进行明确编程即可学习。” 这是一个较旧的非正式定义。
> > ```
>
> Tom Mitchell provides a more modern definition: "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E."
>
> > ```
> > 汤姆·米切尔（Tom Mitchell）提供了一个更现代的定义：“如果某计算机程序在T任务上的性能（由P来衡量）随着经验E的提高而提高，那么据说计算机程序可以从经验E中学习一些任务T和性能指标P。 ”
> > ```

## 2.机器学习的基本概念

### 2.1  特征空间

>- **特征(Feature)：**即属性。每个输入实例的各个组成部分（属性）称作原始特征，基于原始特征还可以扩展出更多的衍生特征
>- **特征向量(Feature Vector)：**由多个特征组成的集合，称作特征向量。
>- **特征空间(Feature Space)：**将特征向量存在的空间称作特征空间。
>
>> * 特征空间中每一维都对应了一个特征(属性)
>>
>> - 特征空间可以和输入空间相同，也可以不同
>> - 需将将实例从输入空间映射到特征空间
>> - 模型实际上是定义于特征空间之上的

### 2.2  假设空间

>  **假设空间(Hypothesis Space)：**由输入空间到输出空间的映射的集合，称作假设空间。
>
>  >- 监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。换句话说，学习的目的就在于找到最好的这样的模型。模型属于由输入空间到输出空间的映射集合，这个集合就是假设空间。假设空间的确定意味着学习范围的确定。
>  >  																																								--李航《统计学习方法》
>  >
>  >- The hypothesis space,which defines the class of functions mapping the input space to the output space. That is, the functions operate on the feature vectors of the input objects, and make predictions according to the format of the output space.
>  >
>  > ​																														--李铁岩Learning to Rank for Information Retrieval
>  >
>  >> ```
>  >> 假设空间，它定义了将输入空间映射到输出空间的函数类别。 即，这些函数对输入对象的特征向量进行运算，并根据输出空间的格式进行预测。
>  >> ```
>  >
>  >* 假设空间指的是问题所有假设组成的空间，我们可以把学习过程看作是在假设空间中搜索的过程,搜索目标是寻找与训练集“匹配”的假设。
>  >  																																											--周志华《机器学习》

## 3.机器学习方法的三要素

> #### 机器学习方法通常都是由模型、策略和算法三部分构成:方法=模型+策略+算法

### 3.1  模型：输入空间到输出空间的映射关系。学习过程即为从假设空间中搜索适合当前数据的假设。

> ![001](F:\视频\图片\001.png)

### 3.2  策略：从假设空间众多的假设中选择到最优的模型的学习标准或规则。

> ##### 要从假设空间中选择一个最合适的模型出来，需要解决以下问题:
>
> > * 评估某个模型对单个训练样本的效果
> > * 评估某个模型对训练集的整体效果
> > * 评估某个模型对包括训练集、预测集在内的所有数据的整体效果
>
> ##### 定义几个指标用来衡量上述问题:
>
> > #### 3.2.1  损失函数：0-1损失函数、平方损失函数、绝对损失函数、对数损失函数等
> >
> > > **损失函数(Loss Function)：**用来衡量预测结果和真实结果之间的差距，其值越小，代表预测结果和真实结果越一致。通常是一个非负实值函数。通过各种方式缩小损失函数的过程被称作**优化**。损失函数记做L(Y,f(x))。
> > >
> > > > **0-1损失函数(0-1 LF)：**预测值和实际值精确相等则“没有损失”为0，否则意味着“完全损失”，为1预测值和实际值精确相等有些过于严格，可以采用两者的差小于某个阈值的方式
> > > >
> > > > > $$
> > > > > L(Y,f(X))=\left\{\begin{matrix}
> > > > > 1,Y\neq f(X) & \\ 
> > > > > 0,Y=f(X) & 
> > > > > \end{matrix}\right.
> > > > > $$
> > > > >
> > > > > $$
> > > > > L(Y,f(X))=\left\{\begin{matrix}
> > > > > 1,|Y-f(X)|\geq T & \\ 
> > > > > 0,|Y-f(X)|< T & 
> > > > > \end{matrix}\right.\mid
> > > > > $$
> > > >
> > > > **绝对值损失函数(Absolute LF)：**预测结果与真实结果差的绝对值。简单易懂，但是计算不方便。
> > > >
> > > > > $$
> > > > > L(Y,f(X))=|Y-f(X)|
> > > > > $$
> > > >
> > > > **平方损失函数(Quadratic LF)：**预测结果与真实结果差的平方。
> > > >
> > > > > $$
> > > > > L(Y,f(X))=(Y-f(X))^{2}
> > > > > $$
> > > > >
> > > > > **平方损失函数优势有：**
> > > > >
> > > > > * 每个样本的误差都是正的，累加不会被抵消
> > > > > * 平方对于大误差的惩罚大于小误差
> > > > > * 数学计算简单、友好，导数为一次函数
> > > >
> > > > **对数损失函数(Logarithmic LF)**或**对数似然损失函数(log-likehood loss function)：**对数函数具有单调性，在求最优化问题时，结果与原始目标一致。可将乘法转化为加法，简化计算:
> > > >
> > > > > $$
> > > > > L(Y,P(Y|X))=-logP(Y|X)
> > > > > $$
> > > >
> > > > **指数损失函数(Exponential LF)：**单调性、非负性的优良性质，使得越接近正确结果误差越小
> > > >
> > > > > $$
> > > > > L(Y,f(X))=e^{-Y*f(x)}
> > > > > $$
> > > >
> > > > **折叶损失函数(Hinge LF)：**也称饺链损失，对于判定边界附近的点的惩罚力度较高，常见于SVM
> > > >
> > > > > $$
> > > > > L(f(x))=max(0,1-f(x))
> > > > > $$
> > > >
> > > > ##### 不同的损失函数有不同的特点,适用于不同的场景：
> > > >
> > > > > * 0-1：理想状况模型
> > > > > * Log：逻辑回归、交叉嫡
> > > > > * Squared：线性回归
> > > > > * Exponential：AdaBoosting 
> > > > > * Hinge：SVM、soft margin
> > > > >
> > > > > ![002](F:\视频\图片\002.png)
> >
> > #### 3.2.2  风险函数：经验风险、期望风险、结构风险
> >
> > > **经验风险(Empirical Risk)：**损失函数度量了单个样本的预测结果，要想衡量整个训练集的预测值与真实值的差异，将整个训练集所有记录均进行一次预测，求取损失函数，将所有值累加，即为经验风险。经验风险越小说明模型f(x)对训练集的拟合程度越好。
> > >
> > > > $$
> > > > R{emp}(f)=\frac{1}{N}\sum \begin{matrix}
> > > > N & \\ 
> > > > i=1 & 
> > > > \end{matrix}L(Y,f(x))
> > > > $$
> > >
> > > **风险函数(Risk Function)：**又称期望损失、期望风险。所有数据集（包括训练集和预测集，遵循联合分布P(X,Y))的损失函数的期望值。
> > >
> > > > $$
> > > > R{exp}(f)=\int \int L(Y,f(X))P(x,y)dxdy
> > > > $$
> > >
> > > **经验风险vs期望风险：**
> > >
> > > > * 期望风险是模型对全局（所有数据集）的效果;经验风险是模型对局部（训练集）的效果
> > > > * 期望风险往往无法计算,即联合分布P(X,Y)通常是未知的;经验风险可以计算
> > > > * 当训练集足够大时，经验风险可以替代期望风险，即局部最优代替全局最优
> > >
> > > **结构风险(Structural Risk)：**在经验风险的基础上，增加一个正则化项(Regularizer)或者叫做惩罚项(Penalty Term)
> > >
> > > > $$
> > > > R{srm}(f)=\frac{1}{N}\sum \begin{matrix}
> > > > N & \\ 
> > > > i=1 & 
> > > > \end{matrix}L(Y,f(X))+\lambda J(f)
> > > > $$
> > > >
> > > > $$
> > > > 其中\lambda 为一个大于0的系数，J(f)表示模型f(x)的复杂度
> > > > $$
> > >
> > > **结构风险vs经验风险：**
> > >
> > > > * 经验风险越小，模型决策函数越复杂,其包含的参数越多
> > > > * 当经验风险函数小到一定程度就出现了过拟合现象
> > > > * 防止过拟合现象的方式，就要降低决策函数的复杂度，让惩罚项J(f)最小化
> > > > * 需要同时保证经验风险函数和模型决策函数的复杂度都达到最小化
> > > > * 把两个式子融合成一个式子得到结构风险函数然后对这个结构风险函数进行最小化
> >
> > #### 3.2.3  正则化项，范数
> >
> > > **正则化项(Regularizer)：**即惩罚函数，该项对模型向量进行惩罚，从而避免过拟合问题。正则化方法会自动削弱不重要的特征变量，自动从许多的特征变量中”提取“重要的特征变量，减小特征变量的数量级。
> > >
> > > > $$
> > > > R{srm}(f)=\frac{1}{N}\sum \begin{matrix}
> > > > N & \\ 
> > > > i=1 & 
> > > > \end{matrix}L(Y,f(X))+\lambda J(f)
> > > > $$
> > >
> > > **范数(Norm)：**
> > >
> > > 规则化函数λJ(f) 有多种选择，一般地，它是模型复杂度的单调递增函数，模型越复杂，该函数的值就越大，惩罚力度相应的越大。常用模型的参数向量的范数。常用的有零范数、一范数、二范数、迹范数、Frobenius范数和核范数等等。
> > >
> > > > $$
> > > > R{srm}(f)=\frac{1}{N}\sum \begin{matrix}
> > > > N & \\ 
> > > > i=1 & 
> > > > \end{matrix}L(Y,f(X))+\lambda J(f)
> > > > $$
> > >
> > > **范数(Norm)：**是数学中的一种基本概念，它定义在赋泛线性空间中，满足①非负性;②齐次性;③三角不等式等条件的量。常常用来度量向量的长度或者大小。
> > >
> > > > $$
> > > > Lp=\sqrt[p]{\sum \begin{matrix}
> > > > n & \\ 
> > > > i=1 & 
> > > > \end{matrix} x_{i}^{p}}
> > > > $$
> > > >
> > > > $$
> > > > L0范数：\left | |x| \right |_{0}=\sqrt[0]{\sum \begin{matrix}
> > > > n & \\ 
> > > > i=1 & 
> > > > \end{matrix}x_{i}^{0}}
> > > > \; \;  \;  \;  \;  \;  \;  \;  ||x||_{0}=\#(i|x_{i}\neq 0)
> > > > $$
> > > >
> > > > $$
> > > > L1范数：\left | |x| \right |_{1}=\sqrt[1]{\sum \begin{matrix}
> > > > n & \\ 
> > > > i=1 & 
> > > > \end{matrix}x_{i}^{1}}
> > > > \; \;  \;  \;  \;  \;  \;  ||x||_{1}=\sum \begin{matrix}
> > > > n & \\ 
> > > > i=1 & 
> > > > \end{matrix}|x_{i}|
> > > > $$
> > > >
> > > > $$
> > > > L2范数：\left | |x| \right |_{2}=\sqrt[2]{\sum \begin{matrix}
> > > > n & \\ 
> > > > i=1 & 
> > > > \end{matrix}x_{i}^{2}}
> > > > $$
> > > >
> > > > * **L0范数：**非0的元素的个数。使用L0范数，期望参数大部分为0，即让参数是稀疏的
> > > > * **L1范数：**各个元素的绝对值之和，使用L1范数，会使参数稀疏。L1也被称为稀疏规则算子。
> > > > * **L2范数：**各元素的平方和求平方根，使得每个元素都很小，但不会等于0，而是接近0。
> > > >
> > > > $$
> > > > min(R_{emp}+\lambda J(f))<==>min(R_{emp})s.t.\lambda J(f)\leq \eta
> > > > $$
> >
> > #### 3.2.4 基本策略
> >
> > > * 经验风险最小（EMR : Empirical Risk Minimization)
> > > * 结构风险最小（SRM : Structural Risk Minimization)
>

### 3.3  算法：学习模型的具体的计算方法，通常是求解最优化问题。

## 4.模型选择

### 4.1  误差

>**误差(Error)：**是模型的预测输出值与其真实值之间的差异。
>
>**训练(Training)：**通过已知的样本数据进行学习，从而得到模型的过程。训练误差(Training Error):模型作用于训练集时的误差。
>**泛化(Generalize)：**由具体的、个别的扩大为一般的，即从特殊都一般，称为泛化。对机器学习的模型来讲，泛化是指模型作用于新的样本数据（非训练集）。
>**泛化误差(Generalization Error)：**模型作用于新的样本数据时的误差。
>
>>![003](F:\视频\图片\003.png)

### 4.2  欠拟合和过拟合

> **模型容量(Model Capacity)：**是指其拟合各种模型的能力。
>
> **过拟合(Overfitting)：**是某个模型在训练集上表现很好，但是在新样本上表现差。模型将训练集的特征学习的太好，导致一些非普遍规律被模型接纳和体现，从而在训练集上表现好，但是对于新样本表现差。反之则称为**欠拟合(Underfitting)**，即模型对训练集的一般性质学习较差，模型作用于训练集时表现不好。

### 4.3  模型选择

> **模型选择(Model Selection)：**针对某个具体的任务，通常会有多种模型可供选择，对同一个模型也会有多组参数，可以通过分析、评估模型的泛化误差，选择泛化误差最小的模型。

### 4.4 评估思路

> 通过实验测试，对模型的泛化误差进行评估，选出泛化误差最小的模型。待测数据集全集未知，使用测试集进行泛化测试，测试误差（Testing Error）即为泛化误差的近似。
>
> #### 4.4.1  留出法
>
> > **留出法(Hold-out)：**将已知数据集分成两个互斥的部分，其中一部分用来训练模型，另一部分用来测试模型，评估其误差，作为泛化误差的估计。
> >
> > * 两个数据集的划分要尽可能保持数据分布一致性，避免因数据划分过程引入为的偏差 
> >   * 保持样本的类别比例相似，即采用分层采样(Stratified Sampleing )
> > * 数据分割存在多种形式会导致不同的训练集、测试集划分，单次留出法结果往往存在偶然性，其稳定性较差，通常会进行若干次随机划分、重复实验评估取平均值作为评估结果
> > * 数据集拆分成两部分，每部分的规模设置会影响评估结果，测试、训练的比例通常为7:3、8:2等
>
> #### 4.4.2  交叉验证法
>
> > **交叉验证法(Cross Validation)：**将数据集划分k 个大小相似的互斥的数据子集，子集数据尽可能保证数据分布的一致性（分层采样），每次从中选取一个数据集作为测试集，其余用作训练集，可以进行k次训练和测试，得到评估均值。该验证方法也称作k折交叉验证( k-fold Cross Validation)。使用不同的划分，重复p次，称为p次k折交叉验证。
>
> #### 4.4.3  留一法
>
> > **留一法(Leave-One-Out, LOO)：**是k折交叉验证的特殊形式，将数据集分成两个，其中一个数据集记录条数为1，作为测试集使用，其余记录作为训练集训练模型。训练出的模型和使用全部数据集训练得到的模型接近，其评估结果比较准确。缺点是当数据集较大时，训练次数和计算规模较大。
>
> #### 4.4.4  自助法
>
> > **自助法(Bootstrapping)：**是一种产生样本的抽样方法，其实质是有放回的随机抽样。即从已知数据集中随机抽取一条记录，然后将该记录放入测试集同时放回原数据集，继续下一次抽样，直到测试集中的数据条数满足要求。
> >
> > 通过有放回的抽样获得的训练集去训练模型，不在训练集中的数据（总数量的1/3强）去用于测试，这样的测试结果被称作**包外估计(Out-of-Bag Estimate , OOB)**

### 4.5 几种方法的适用场景

> #### 4.5.1  留出法：
>
> > * 实现简单、方便，在一定程度上能评估泛化误差
> > * 测试集和训练集分开，缓解了过拟合
> > * 一次划分，评估结果偶然性大
> > * 数据被拆分后，用于训练、测试的数据更少了
>
> #### 4.5.2  交叉验证法(留一法)：
>
> > * k可以根据实际情况设置，充分利用了所有样本
> > * 多次划分，评估结果相对稳定
> > * 计算比较繁琐，需要进行k次训练和评估
>
> #### 4.5.3  自助法：
>
> > * 样本量较小时可以通过自助法产生多个自助样本集，且有约36.8%的测试样本
> > * 对于总体的理论分布没有要求
> > * 无放回抽样引入了额外的偏差
>
> #### 4.5.4  几种方法的选择
>
> > * 已知数据集数量充足时，通常采用留出法或者k折交叉验证法
> > * 对于已知数据集较小且难以有效划分训练集/测试集的时候，采用自助法
> > * 对于已知数据集较小且可以有效划分训练集/测试集的时候，采用留一法

## 4.6  性能度量

> **性能度量(Performance Measure)：**评价模型泛化能力的标准。对于不同的模型，有不同的评价标准，不同的评价标准将导致不同的评价结果。模型的好坏是相对的，取决于对于当前任务需求的完成情况。
>
> 回归模型的性能度量通常选用**均方误差(Mean Squared Error)**。
>
> 给定样例集D={(x1,y1), (x2,y2),...,(xm,ym)}，模型为f，其性能度量均方误差为:
>
> > $$
> > E(f;D)=\frac{1}{m}\sum_{i=1}^{m}(f(x_{i})-y_{i})^{2}
> > $$

#### 4.6.1  分类算法的性能度量

> **分类算法常用的性能度量：**
>
> > * **错误率：**分类错误的样本占总样本数的比例
> >
> > > $$
> > > E(f;D)=\frac{1}{m}\prod (f(x_{i})\neq y_{i})
> > > $$
> >
> > * **精度：**分类正确的样本占总样本数的比例
> >
> > > $$
> > > acc(f;D)=\frac{1}{m}\prod (f(x_{i})\neq y_{i})=1-E(f;D)
> > > $$
> >
> > * **查准率：**预测结果为正的样本中实际值也为正的比例
> > * **查全率：**实际值为正的样本中被预测为正的样本的比例
> > * **P-R曲线：**查准率-查询率曲线
> > * **混淆矩阵：**将预测分类结果和实际分类结果做成矩阵的形式显示
> > * **Fβ- score：**β值的不同体现了对查全率和查准率的不同倾向
> >
> > > $$
> > > F_{\beta }=\frac{(1+\beta ^{2})*P*R}{\beta ^{2}*P+R}
> > > $$
> >
> > * **受试者特征曲线(ROC)和曲线下面积(AUC)：** TPR-FPR曲线（真正例率-假正例率曲线)
> > * **代价曲线：**不同类型的预测错误对结果影响不同而增加代价 (cost)，绘制 P(+)cost - cost_norm曲线
> > * ......

#### 4.6.2  聚类算法的性能度量

> **聚类算法的性能度量：**
>
> > * **外部指标(External Index)：**将聚类结果同某个参考模型进行比较
> >
> >   * **Jaccard系数( Jaccrd Coefficient , JC )：**
> >
> >     > $$
> >     > JC=\frac{a}{a+b+c}
> >     > $$
> >
> >   * **FM指数（Fowlkes and Mallows Index ,FMI) ：**
> >
> >     > $$
> >     > FMI=\sqrt{\frac{a}{a+b}*\frac{a}{a+c}}
> >     > $$
> >
> >   * **Rand指数(Rand Index )：**
> >
> >     > $$
> >     > RI=\frac{2(a+b)}{m(m-1)}
> >     > $$
> >
> > * **内部指标(Internal Index)：**不使用参考模型直接考察聚类结果
> >
> >   * **DB指数（Davise-Bouldin Index ,DBI)：**
> >
> >     > $$
> >     > DBI=\frac{1}{k}\sum \begin{matrix}
> >     > k & \\ 
> >     > 1 & 
> >     > \end{matrix}\underset{j\neq 1}{max}(\frac{avg(C_{i})+avg(C_{i})}{d_{cen(\mu_{i},\mu_{j})}})
> >     > $$
> >
> >   * **Dunn指数（Dunn Index , DI)：**
> >
> >     > $$
> >     > DI=\underset{i\leq i\leq k}{min}\{\underset{j\neq i}{min}(\frac{d_{min}(C_{i},C_{j})}{\underset{1\leq l\leq k}{max} 
> >     > \;diam(C_{l})})\}
> >     > $$

### 5.模型比较

> #### 选择合适的评估方法和相应的性能度量，计算出性能度量后直接比较。
>
> ##### 存在以下问题:
>
> * 模型评估得到的是测试集上的性能，并非严格意义上的泛化性能，两者并不完全相同
> * 测试集上的性能与样本选取关系很大，不同的划分，测试结果会不同，比较缺乏稳定性
> * 很多模型本身有随机性，即使参数和数据集相同，其运行结果也存在差异

#### 5.1  假设检验

> **统计假设检验(Hypothesis Test)：**事先对总体的参数或者分布做一个假设，然后基于已有的样本数据去判断这个假设是否合理。即样本和总体假设之间的不同是纯属机会变异(因为随机性误差导致的不同)，还是两者确实不同。常用的假设检验方法有t-检验法、x2检验法(卡方检验)、F-检验法等。
>
> ##### 基本思想：
>
> * 从样本推断整体
> * 通过反正法推断假设是否成立
> * 小概率事件在一次试验中基本不会发生不轻易拒绝原假设
> * 通过显著性水平定义小概率事件不可能发生的概率
> * 全称命题只能被否定而不能被证明
>
> ##### 5.1.1  假设检验步骤：
>
> 1. 建立假设
>
>    > 根据具体的问题，建立假设∶
>    >
>    > * **原假设(Mull Hypothesis)：**搜集证据希望推翻的假设，记作H0
>    >
>    > * **备择假设(Alternative Hypothesis)：**搜集证据予以支持的假设，记作H1
>    >
>    > * **假设的形式：**
>    >   $$
>    >   双尾假设:\;H_{0}:\mu=\mu_{0},\,H_{1}:\mu\neq\mu_{0}\;\;\;不等于、有差异
>    >   $$
>    >
>    > $$
>    > 左侧单尾假设:\;H_{0}:\mu\geq\mu_{0},\,H_{1}:\mu<\mu_{0}\;\;\;降低、减少
>    > $$
>    >
>    > $$
>    > 右侧单尾假设:\;H_{0}:\mu\leq\mu_{0},\,H_{1}:\mu>\mu_{0}\;\;\;提高、增加
>    > $$
>
> 2. 确定检验水平
>
>    > 确定检验水准：
>    > **检验水准(Size of a Test)：**又称**显著性水平(Significance Level)**，记作α，是指原假设正确，但是最终被拒绝的概率。在做检验的过程中，会犯两种错误∶
>    >
>    > * 原假设为真，被拒绝，称作第一类错误，其概率记作α，即为显著性水平，取值通常为0.05、0.025，0.01等
>    > * 原假设为假，被接受，称作第二类错误，其概率记作β，即为检验功效(power of a test)
>
> 3.  构造统计量
>
>    > **构造统计量：**
>    > 	根据资料类型、研究设计方案和统计推断的目的，选用适当检验方法和计算相应的统计量。
>    >
>    > 常见检验方法︰
>    >
>    > * t检验：小样本(30)，总体标准差σ未知的正态分布
>    > * F检验：即方差分析，检验两个正态随机变量的总体方差是否相等的一种假设检验方法
>    > * Z检验：大样本(>=30) 平均值差异性检测，又称u检验
>    > * X^2检验：即卡方检验，用于非参数检验，主要是比较两个及两个以上样本率以及两个分类变量的关联性分析
>
> 4.  计算p值
>
>    > **关于p值：**
>    >
>    > * 用来判定假设检验结果的参数，和显著性水平α相比
>    > * 在原假设为真的前提下出现观察样本以及更极端情况的概率
>    > * 如果p值很小，说明原假设出现的概率很小，应该拒绝，p值越小，拒绝原假设的理由越充足
>
> 5. 得到结论
>
>    > **得到结论：**
>    >
>    > * 如果p值小于等于显著水平α，表明x小概率事件发生，拒绝原假设
>    > * 统计量的值如果落在拒绝域内或者临界值，则拒绝原假设，落在接受域则不能拒绝原假设

### 6.偏差、方差和噪声

#### 6.1  概念

> **偏差(Bias)：**描述的是根据样本拟合出的模型的输出预测结果的期望与样本真实结果的差距，即在样本上拟合的好不好。
>
> **方差(Variance)：**模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。
>
> **噪声(Noise)：**为真实标记与数据集中的实际标记间的偏差。通常由多种因素综合影响造成，不可去除。
>
> **偏差**度量了学习算法的**期望**预测与真实结果的偏离程度，刻画了学习算法本身的拟合能力。
>
> **方差**度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。
>
> **噪声**表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。

#### 6.2  泛化误差组成推导*

> 数据集D中的测试样本x的标记为yD,y为x的真实标记，f(x;D)为基于数据集D学习的模型f对x的预测值。
>
> 以回归算法为例，其**期望预测**为：
>
> > $$
> > \overline{f}(x)=E_{D}[f(x;D)]
> > $$
>
> 使用样本数相同的不同训练集产生的**方差**为：
>
> > $$
> > var(x)=E_{D}[(f(x;D)-\overline{f}(x))^{2}]
> > $$
>
> **噪声：**
>
> > $$
> > \varepsilon ^{2}=E_{D}[(y_{D}-y)^{2}]
> > $$
>
> 回归方程的噪声的期望：
>
> > $$
> > E_{D}(y_{D}-y)=0
> > $$
>
> 期望输出与真实标记的**偏差**：
>
> > $$
> > bias^{2}(x)=E_{D}(\overline{f}(x)-y)^{2}
> > $$
>
>  **期望泛化误差：**预测值和真实值的差的平方和即为泛化误差
>
> > $$
> > E(f;D)=E_{D}[(f(x;D)-y_{D})^{2}]\\=E_{D}[(f(x;D)-\overline{f}(x)+\overline{f}(x)-y_{D})^{2}]
> > \\=E_{D}[(f(x;D)-\overline{f}(x))^{2}]+E_{D}[(\overline{f}(x)-y_{D})^{2}]+E_{D}[2(f(x;D)-\overline{f}(x))(\overline{f}(x)-y_{D})]\\=E_{D}[(f(x;D)-\overline{f}(x))^{2}]+E_{D}[(\overline{f}(x)-y_{D})^{2}]\\=E_{D}[(f(x;D)-\overline{f}(x))^{2}]+E_{D}
> > [(\overline{f}(x)-y+y-y_{D})^{2}]\\=E_{D}[(f(x;D)-\overline{f}(x))^{2}]+E_{D}[(\overline{f}(x)-y)^{2}]+E_{D}[(y_{D}-y)^{2}]+2E_{D}[(\overline{f}(x)-y)(y-y_{D})]\\=
> > E_{D}[(f(x;D)-\overline{f}(x))^{2}]+E_{D}[(\overline{f}(x)-y)^{2}]+E_{D}[(y_{D}-y)^{2}]
> > \\=var(x)+bias^{2}(x)+\varepsilon ^{2}
> > $$
> >
>

### 6.3  特点

> * **偏差：**体现的是最终结果和实际结果的差异，偏差越小，和真实结果越接近
> * **方差：**体现的是整体水平波动，方差越小，结果稳定性越好
> * 期望的模型结果为：**低偏差，低方差**
> * **偏差**体现的是拟合程度优劣，通常模型越复杂，偏差越小。当偏差较大时，即预期输出和实际结果偏离较大，称之为欠拟合。
> * **方差**体现的是模型的稳定程度。通常模型越简单，方差越小。当方差较大时，模型不稳定，即对一些新数据的预测不稳定。偏差小，方差大的情况即为过拟合。